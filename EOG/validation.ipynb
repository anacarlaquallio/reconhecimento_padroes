{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação dos dados EOG\n",
    "\n",
    "Neste notebook está incluído os seguintes passos:\n",
    "- Aplicação de características;\n",
    "- Criação do vetor de características;\n",
    "- Normalização de dados;\n",
    "- Seleção de características;\n",
    "- Classificação dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma característica é uma propriedade individual mensurável ou característica de um fenômeno que está sendo observado. Em nosso caso de EOG, uma característica pode ser extraída no domínio do tempo ou no domínio da frequência. As características a seguir foram retiradas do artigo *EMG Feature Extraction for Tolerance of White Gaussian Noise* \\[1\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio do tempo\n",
    "\n",
    "1. Willison Amplitude (WAMP)\n",
    "\n",
    "    > $ \\sum_{i=1}^{N-1}f(|x_i - x_{i+1}|) $\n",
    "    \n",
    "    > $ f(x) = \\begin{cases} 1 & \\text{if } x \\gt threshold \\\\ 0 & \\text{otherwise} \\end{cases} $\n",
    "\n",
    "2. Variance of EMG (VAR)\n",
    "\n",
    "    > $ \\frac{1}{N-1}\\sum_{i=1}^{N}x_i^2 $\n",
    "\n",
    "3. Root Mean Square (RMS)\n",
    "\n",
    "    > $ \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}|x_i|^2} $\n",
    "\n",
    "4. Waveform Length (WL)\n",
    "    \n",
    "    > $ \\sum_{i=1}^{N-1}|x_{i+1} - x_i| $\n",
    "\n",
    "5. Zero Crossing (ZC)\n",
    "\n",
    "    > $ \\sum_{i=1}^{N}sgn(x_i) $\n",
    "    \n",
    "    > $ sgn(x) = \\begin{cases} 1 & \\text{if } x_i * x_{i+1} \\leq 0 \\\\ 0 & \\text{otherwise} \\end{cases} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio da frequência\n",
    "\n",
    "1. Median Frequency (FMD): energia média do sinal no domínio da frequência\n",
    "\n",
    "    > $ \\frac{1}{2}\\sum_{j=1}^{M}PSD_j $\n",
    "\n",
    "2. Mean Frequency (FMN)\n",
    "\n",
    "    > $\\sum_{j=1}^{M}f_j PSD_j / \\sum_{j=1}^{M}PSD_j$\n",
    "    \n",
    "    > $ f_j = j * SampleRate / 2 * M $\n",
    "\n",
    "3. Modified Median Frequency (MMDF)\n",
    "\n",
    "    > $ \\frac{1}{2}\\sum_{j=1}^{M}A_j $\n",
    "    \n",
    "    > $ A_j = Amplitude\\ do\\ espectro\\ j $\n",
    "\n",
    "4. Modified Frequency Mean (MMNF)\n",
    "\n",
    "    > $ \\sum_{j=1}^{M}f_jAj / \\sum_{j=1}^{M}Aj $\n",
    "\n",
    "\n",
    "\\[1\\] Phinyomark, Angkoon & Limsakul, Chusak & Phukpattaranont, P.. (2008). EMG Feature Extraction for Tolerance of White Gaussian Noise.\n",
    "[Disponível neste link](https://www.researchgate.net/publication/263765853_EMG_Feature_Extraction_for_Tolerance_of_White_Gaussian_Noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarefa 1**: Descrever as características de acordo com o artigo citado e outros disponíveis relacionados. O que está querendo \"ser visto\" em cada característica? Qual é o significado matemático de cada uma delas?\n",
    "\n",
    "**Domínio do tempo**\n",
    "- Willison Amplitude (WAMP): é uma medida estatística que quantifica a quantidade de variação absoluta em uma série temporal. Ela é frequentemente usada em análise de séries temporais para identificar mudanças abruptas ou picos. Essencialmente, o WAMP é calculado somando as diferenças absolutas entre pontos consecutivos na série temporal, excluindo o primeiro ponto, já que não há ponto anterior para comparar. Significado matemático: $N$ é o número total de pontos na série temporal; $x_i$​ é o valor da série temporal no tempo $t$; $x_{i−1​}$ é o valor da série temporal no tempo $i-1$ e $∣\\cdot∣$ denota o valor absoluto.\n",
    "\n",
    "- Variance of EMG (VAR): a variância (VAR) da amplitude do sinal eletromiográfico é uma medida estatística que quantifica a dispersão dos valores de amplitude no sinal EMG. A variância é uma medida de quão distantes os valores individuais do sinal estão da média. Se a variância for alta, isso indica que os valores individuais estão mais dispersos, enquanto uma variância baixa indica que os valores estão mais próximos da média. Significado matemático: $N$ e $x_i$ são, respectivamente, o comprimento e o enésimo valor amostral do sinal EMG.\n",
    "\n",
    "- Root Mean Square (RMS): a raiz quadrada da média dos quadrados é uma medida estatística utilizada para representar a magnitude de um conjunto de valores. No contexto de sinais, como o sinal eletromiográfico (EMG) ou de áudio, o RMS é frequentemente usado para quantificar a amplitude eficaz do sinal. Significado matemático: $N$ e $x_i$ são, respectivamente, o comprimento e o enésimo valor amostral do sinal EMG.\n",
    "\n",
    "- Waveform Length (WL): é uma medida que quantifica a complexidade ou o comprimento total de uma forma de onda. É frequentemente utilizada em análises de sinais, como sinais eletromiográficos (EMG) ou outros tipos de sinais biomédicos. A fórmula envolve calcular a soma das diferenças absolutas entre amostras consecutivas na forma de onda. Essa medida é sensível às variações locais na amplitude da forma de onda e pode ser usada para avaliar a complexidade ou rugosidade do sinal. Quanto mais irregularidades ou mudanças abruptas houver na forma de onda, maior será o valor do Waveform Length. Significado matemático: $N$ e $x_i$ são, respectivamente, o comprimento e o enésimo valor amostral do sinal EMG.\n",
    "\n",
    "- Zero Crossing (ZC): é uma medida utilizada para quantificar a frequência de mudanças de polaridade em um sinal, como uma forma de onda. Em sinais de áudio, por exemplo, um cruzamento por zero ocorre sempre que o sinal muda de positivo para negativo ou vice-versa. Em termos simples, um zero crossing é o ponto em que a amplitude de um sinal muda de sinal. Significado matemático: $N$ é o número total de amostras no sinal; $x_i$ representa cada amostra individual no sinal; $sign(x_i)$ é a função de sinal, que retorna $-1$ se $x_i$​ for negativo, $0$ se for zero e $1$ se for positivo.\n",
    "\n",
    "\n",
    "**Domínio da frequência**\n",
    "- Median Frequency (FMD): é a frequência na qual o espectro é dividido em duas regiões médias. Significado matemático: o $PSD$ aqui é entendido como $|w^2|$. \n",
    "\n",
    "- Mean Frequency (FMN): é uma medida da frequência média ponderada no espectro de potência do sinal. Ela é frequentemente usada para caracterizar a distribuição de energia em um sinal ao longo das diferentes frequências, fornecendo uma medida de centralidade das frequências predominantes no sinal. Significado matemático: o $PSD$ é entendido como $|w^2|$ e $f_j$ é o espectro de frequência no compartimento de frequência $j$.\n",
    "\n",
    "- Modified Median Frequency (MMDF): é a frequência na qual o espectro é dividido em duas regiões com amplitude igual. Significado matemático: $A_j$ é o espectro de amplitude do EMG diante da frequência $j$.\n",
    "\n",
    "- Modified Frequency Mean (MMNF): é estimado como a soma do produto do espectro de amplitude e frequência dividida pela soma total da intensidade do espectro. Significado matemático: $A_j$ e $f_j$ são o espectro de amplitude EMG e o espectro de frequência no compartimento de frequência $j$, respectivamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando as características\n",
    "\n",
    "É necessário implementar as características, geralmente em formato de funções ou métodos, para que seja possível aplicar tais funções aos dados de entrada e obter as características resultantes. A seguir temos a implementação das características `VAR` & `RMS` (domínio do tempo) e `FDM` & `MMDF` (domínio da frequência).\n",
    "\n",
    "**Tarefa 2**: Implemente todas as características apresentadas neste tutorial em formato de funções. Sinta-se livre também para buscar e implementar características além das apresentadas, citando as fontes de tais características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import prod\n",
    "import numpy as np\n",
    "\n",
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "def func_j(w):\n",
    "    sample_rate = np.arange(1, w.shape[-1]+1) * 200\n",
    "    return sample_rate / 2 * w.shape[-1]\n",
    "\n",
    "# funções de extração de características\n",
    "def wamp(time, threshold):\n",
    "    return np.sum(np.abs(np.diff(time)) > threshold, axis=-1)\n",
    "\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape) - 1))\n",
    "\n",
    "def wl(x):\n",
    "    return np.sum(np.abs(np.diff(x, axis=-1)), axis=-1)\n",
    "\n",
    "def zc(x):\n",
    "    return np.count_nonzero(np.diff(np.sign(x), axis=-1) != 0, axis=-1)\n",
    "\n",
    "def log_det(x):\n",
    "    from math import e\n",
    "    return e ** (np.sum(np.log10(np.abs(x)), axis=-1) /  np.prod(x.shape))\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def fmn(w):\n",
    "    return  np.sum(func_j(w)* PSD(w), axis=-1)/ fmd(w) * 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "def mmnf(w):\n",
    "    return np.sum(func_j(w) * np.abs(w),  axis=-1) / mmdf(w) * 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vetor de características\n",
    "\n",
    "Ao final da implementação e seleção das características, deve ser escolhida as características e então teremos um vetor com todas elas implementadas.\n",
    "\n",
    "O vetor de características estará organizado da seguinte forma (exemplo p/ VAR, RMS, RDM e MMDF) (1 e 2 porque são dois eletrodos)\n",
    "\n",
    "| ID sample | VAR1 | RMS1 | FMD1 | MMDF1 | VAR2 | RMS2 | FMD2 | MMDF2 | Classe |\n",
    "|:---------:|:----:|:----:|:----:|:-----:|------|------|------|-------|:------:|\n",
    "|     1     |  v1  |  v1  |  v1  |   v1  | v1   | v1   | v1   | v1    |    0   |\n",
    "|     2     |  v2  |  v2  |  v2  |   v2  | v2   | v2   | v2   | v2    |    0   |\n",
    "|    ...    |  ... |  ... |  ... |  ...  | ...  | ...  | ...  | ...   |   ...  |\n",
    "|     N     |  vN  |  vN  |  vN  |   vN  | vN   | vN   | vN   | vN    |    7   |\n",
    "\n",
    "\n",
    "### Participante 1\n",
    "#### Implementação do vetor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos vetores orinais (28, 2, 8, 64) (28, 2, 8, 33)\n",
      "(28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Carregando dados do participante 1\n",
    "x1 = np.load(\"datasets/p1_time.npy\")\n",
    "w1 = np.load(\"datasets/p1_freq.npy\")\n",
    "\n",
    "# Extraindo características do participante 1\n",
    "data_wamp1 = wamp(x1, np.median(x1))\n",
    "data_var1 = var(x1)\n",
    "data_rms1 = rms(x1)\n",
    "data_wl1 = wl(x1)\n",
    "data_zc1 = zc(x1)\n",
    "\n",
    "data_fmd1 = fmd(w1)\n",
    "data_fmn1 = fmn(w1)\n",
    "data_mmdf1 = mmdf(w1)\n",
    "data_mmnf1 = mmnf(w1)\n",
    "\n",
    "print(\"Shape dos vetores orinais\", x1.shape, w1.shape)\n",
    "\n",
    "print(data_wamp1.shape, data_var1.shape, data_rms1.shape, data_wl1.shape, data_zc1.shape, data_fmd1.shape, data_fmn1.shape, data_mmdf1.shape, data_mmnf1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 28, 2, 8)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# União do vetor de características inicial (concatenação de data) para o participante 1\n",
    "\n",
    "features = np.array([data_wamp1, data_var1, data_rms1, data_wl1, data_zc1, data_fmd1, data_fmn1, data_mmdf1, data_mmnf1])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 18)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organização das dimensões\n",
    "features = features.transpose(1, 3, 0, 2)\n",
    "\n",
    "# Criar vetor de características definitivo\n",
    "features = features.reshape(features.shape[0] * features.shape[1], features.shape[2] * features.shape[3])\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 2, 3, 3, 1, 0, 3, 0, 0, 1, 2, 3, 2, 1, 0, 2, 1, 3, 1, 0, 1, 2, 0, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "labels_str = ['dir', 'esq', 'cima', 'baixo', 'cima', 'baixo',\n",
    "'baixo', 'esq', 'dir', 'baixo', 'dir', 'dir', 'esq', 'cima',\n",
    "'baixo', 'cima', 'esq', 'dir', 'cima', 'esq', 'baixo', 'esq',\n",
    "'dir', 'esq', 'cima', 'dir', 'cima', 'baixo']\n",
    "\n",
    "# transformando para numérico\n",
    "lab_dict = {'dir': 0, 'esq': 1, 'cima': 2, 'baixo': 3}\n",
    "labels_num = [lab_dict[item] for item in labels_str]\n",
    "\n",
    "print(labels_num)\n",
    "\n",
    "# criação do vetor de labels final\n",
    "y = np.repeat(labels_num, int(features.shape[0] / len(labels_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(features)\n",
    "y = scaler.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação utilizando SVM padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 26.67%\n"
     ]
    }
   ],
   "source": [
    "# Utilizando SVM padrão\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Criando os rótulos usando np.repeat\n",
    "y = np.repeat(labels_num, int(features.shape[0] / len(labels_num)))\n",
    "\n",
    "# Divisão dos dados em conjunto de treino e teste (opcional)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criando e treinando o modelo SVM\n",
    "svm_model = SVC(kernel='linear')  # Você pode escolher o tipo de kernel desejado\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliando o modelo (opcional)\n",
    "accuracy = svm_model.score(X_test, y_test)\n",
    "print(f'Acurácia do modelo: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação utilizando Grid Search e seleção de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.39285714285714285\n",
      "Best parameters: {'C': 10, 'gamma': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "# Utilizando Grid Search com SVM e seleção de características\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm, metrics\n",
    "import numpy as np\n",
    "\n",
    "max_k = X.shape[1]\n",
    "start = int(max_k / 2)\n",
    "end = max_k + 1\n",
    "\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "\n",
    "for k in range(start, end):\n",
    "    X_new = SelectKBest(f_regression, k=k).fit_transform(X, y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_new, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    param_grid = [\n",
    "        {'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "        {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['linear', 'rbf', 'poly']},\n",
    "    ]\n",
    "\n",
    "    grid = GridSearchCV(svm.SVC(), param_grid, cv=5)\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    # Predição\n",
    "    y_pred = grid.predict(x_test)\n",
    "    current_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    if current_acc > best_acc:\n",
    "        best_acc = current_acc\n",
    "        best_params = grid.best_params_\n",
    "\n",
    "print(\"Best accuracy:\", best_acc)\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação utilizando validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 19.64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Dividindo os dados normalizados em 4 conjuntos (folds) para validação cruzada\n",
    "cv = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# Lista para armazenar as acurácias para cada fold\n",
    "acc_scores = []\n",
    "\n",
    "# Loop pelos folds\n",
    "for train_idx, test_idx in cv.split(X, y):\n",
    "    # Divida os dados normalizados em conjunto de treinamento e conjunto de teste para este fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Treine o modelo SVM no conjunto de treinamento\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Faça previsões no conjunto de teste\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "\n",
    "    # Calcule a acurácia do modelo para este fold\n",
    "    fold_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Armazene a acurácia deste fold na lista\n",
    "    acc_scores.append(fold_accuracy)\n",
    "\n",
    "mean_acc = np.mean(acc_scores)\n",
    "\n",
    "# Imprima a média\n",
    "print(f\"Acurácia média: {mean_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação com RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 29.41%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(svm.SVC(kernel=\"linear\"), step=0.0001, n_features_to_select=500)\n",
    "X_final = rfe.fit_transform(X, y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42)\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participante 2\n",
    "#### Implementação do vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos vetores orinais (28, 2, 8, 64) (28, 2, 8, 33)\n",
      "(28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8) (28, 2, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Carregando dados do participante 1\n",
    "x2 = np.load(\"datasets/p2_time.npy\")\n",
    "w2 = np.load(\"datasets/p2_freq.npy\")\n",
    "\n",
    "# Extraindo características do participante 1\n",
    "data_wamp2 = wamp(x2, np.median(x2))\n",
    "data_var2 = var(x2)\n",
    "data_rms2 = rms(x2)\n",
    "data_wl2 = wl(x2)\n",
    "data_zc2 = zc(x2)\n",
    "\n",
    "data_fmd2 = fmd(w2)\n",
    "data_fmn2 = fmn(w2)\n",
    "data_mmdf2 = mmdf(w2)\n",
    "data_mmnf2 = mmnf(w2)\n",
    "\n",
    "print(\"Shape dos vetores orinais\", x2.shape, w2.shape)\n",
    "\n",
    "print(data_wamp2.shape, data_var2.shape, data_rms2.shape, data_wl2.shape, data_zc2.shape, data_fmd2.shape, data_fmn2.shape, data_mmdf2.shape, data_mmnf2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 28, 2, 8)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# União do vetor de características inicial (concatenação de data) para o participante 1\n",
    "\n",
    "features = np.array([data_wamp2, data_var2, data_rms2, data_wl2, data_zc2, data_fmd2, data_fmn2, data_mmdf2, data_mmnf2])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 18)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organização das dimensões\n",
    "features = features.transpose(1, 3, 0, 2)\n",
    "\n",
    "# Criar vetor de características definitivo\n",
    "features = features.reshape(features.shape[0] * features.shape[1], features.shape[2] * features.shape[3])\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 2, 3, 3, 1, 0, 3, 0, 0, 1, 2, 3, 2, 1, 0, 2, 1, 3, 1, 0, 1, 2, 0, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "labels_str = ['dir', 'esq', 'cima', 'baixo', 'cima', 'baixo',\n",
    "'baixo', 'esq', 'dir', 'baixo', 'dir', 'dir', 'esq', 'cima',\n",
    "'baixo', 'cima', 'esq', 'dir', 'cima', 'esq', 'baixo', 'esq',\n",
    "'dir', 'esq', 'cima', 'dir', 'cima', 'baixo']\n",
    "\n",
    "# transformando para numérico\n",
    "lab_dict = {'dir': 0, 'esq': 1, 'cima': 2, 'baixo': 3}\n",
    "labels_num = [lab_dict[item] for item in labels_str]\n",
    "\n",
    "print(labels_num)\n",
    "\n",
    "# criação do vetor de labels final\n",
    "y = np.repeat(labels_num, int(features.shape[0] / len(labels_num)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(features)\n",
    "y = scaler.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação utilizando SVM padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 33.33%\n"
     ]
    }
   ],
   "source": [
    "# Utilizando SVM padrão\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Criando os rótulos usando np.repeat\n",
    "y = np.repeat(labels_num, int(features.shape[0] / len(labels_num)))\n",
    "\n",
    "# Divisão dos dados em conjunto de treino e teste (opcional)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criando e treinando o modelo SVM\n",
    "svm_model = SVC(kernel='linear')  # Você pode escolher o tipo de kernel desejado\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliando o modelo (opcional)\n",
    "accuracy = svm_model.score(X_test, y_test)\n",
    "print(f'Acurácia do modelo: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação utilizando Grid Search e seleção de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.35714285714285715\n",
      "Best parameters: {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Utilizando Grid Search com SVM e seleção de características\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm, metrics\n",
    "import numpy as np\n",
    "\n",
    "max_k = X.shape[1]\n",
    "start = int(max_k / 2)\n",
    "end = max_k + 1\n",
    "\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "\n",
    "for k in range(start, end):\n",
    "    X_new = SelectKBest(f_regression, k=k).fit_transform(X, y)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_new, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    param_grid = [\n",
    "        {'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "        {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['linear', 'rbf', 'poly']},\n",
    "    ]\n",
    "\n",
    "    grid = GridSearchCV(svm.SVC(), param_grid, cv=5)\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    # Predição\n",
    "    y_pred = grid.predict(x_test)\n",
    "    current_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "    if current_acc > best_acc:\n",
    "        best_acc = current_acc\n",
    "        best_params = grid.best_params_\n",
    "\n",
    "print(\"Best accuracy:\", best_acc)\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação utilizando validaçãp cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 23.21%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Dividindo os dados normalizados em 4 conjuntos (folds) para validação cruzada\n",
    "cv = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# Lista para armazenar as acurácias para cada fold\n",
    "acc_scores = []\n",
    "\n",
    "# Loop pelos folds\n",
    "for train_idx, test_idx in cv.split(X, y):\n",
    "    # Divida os dados normalizados em conjunto de treinamento e conjunto de teste para este fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Treine o modelo SVM no conjunto de treinamento\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Faça previsões no conjunto de teste\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "\n",
    "    # Calcule a acurácia do modelo para este fold\n",
    "    fold_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Armazene a acurácia deste fold na lista\n",
    "    acc_scores.append(fold_accuracy)\n",
    "\n",
    "mean_acc = np.mean(acc_scores)\n",
    "\n",
    "# Imprima a média\n",
    "print(f\"Acurácia média: {mean_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação com RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 23.53%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(svm.SVC(kernel=\"linear\"), step=0.0001, n_features_to_select=500)\n",
    "X_final = rfe.fit_transform(X, y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42)\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(f\"Acurácia: {accuracy_score(y_test, y_pred):.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
